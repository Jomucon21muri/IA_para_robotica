# üõ°Ô∏è √âtica, Seguridad y Buenas Pr√°cticas - Robot Humanoide

## Prop√≥sito

Garantizar que el desarrollo y operaci√≥n del robot humanoide sean seguros, √©ticos y responsables. Este m√≥dulo es CR√çTICO y NO OPCIONAL.

## √Årea de Conocimiento

Este m√≥dulo implementa el pilar 11: **Seguridad y √âtica** (ver [recursos_conocimientos.md](../00_Gestion_Proyecto/recursos_conocimientos.md)).

## Estructura del Directorio

```
12_Etica_Seguridad/
‚îú‚îÄ‚îÄ README.md (este archivo)
‚îú‚îÄ‚îÄ risk_assessment/
‚îÇ   ‚îú‚îÄ‚îÄ fmea_analisis.md        # Failure Mode and Effects Analysis
‚îÇ   ‚îú‚îÄ‚îÄ riesgos_mecanicos.md
‚îÇ   ‚îú‚îÄ‚îÄ riesgos_electricos.md
‚îÇ   ‚îî‚îÄ‚îÄ riesgos_software.md
‚îú‚îÄ‚îÄ safety_checklists/
‚îÇ   ‚îú‚îÄ‚îÄ pre_prueba.md           # Checklist obligatorio pre-prueba
‚îÇ   ‚îú‚îÄ‚îÄ operacion_diaria.md
‚îÇ   ‚îú‚îÄ‚îÄ mantenimiento.md
‚îÇ   ‚îî‚îÄ‚îÄ transporte.md
‚îú‚îÄ‚îÄ safety_procedures/
‚îÇ   ‚îú‚îÄ‚îÄ emergency_stop.md       # Procedimiento de parada de emergencia
‚îÇ   ‚îú‚îÄ‚îÄ battery_handling.md     # Manejo seguro de bater√≠as LiPo
‚îÇ   ‚îú‚îÄ‚îÄ electrical_safety.md
‚îÇ   ‚îî‚îÄ‚îÄ physical_safety.md
‚îú‚îÄ‚îÄ ethics/
‚îÇ   ‚îú‚îÄ‚îÄ principios_eticos.md    # Principios √©ticos del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ privacidad_datos.md     # Pol√≠tica de privacidad
‚îÇ   ‚îú‚îÄ‚îÄ ai_ethics.md            # √âtica en IA
‚îÇ   ‚îî‚îÄ‚îÄ compliance.md           # Normativas y est√°ndares
‚îú‚îÄ‚îÄ incident_reports/
‚îÇ   ‚îú‚îÄ‚îÄ template.md             # Plantilla de reporte
‚îÇ   ‚îî‚îÄ‚îÄ 2026-02-27_example.md   # Ejemplo
‚îú‚îÄ‚îÄ standards/
‚îÇ   ‚îú‚îÄ‚îÄ iso_15066.md            # Robots colaborativos
‚îÇ   ‚îú‚îÄ‚îÄ iso_13482.md            # Robots de cuidado personal
‚îÇ   ‚îî‚îÄ‚îÄ safety_limits.md        # L√≠mites de seguridad definidos
‚îî‚îÄ‚îÄ documentation/
    ‚îú‚îÄ‚îÄ safety_manual.md        # Manual de seguridad completo
    ‚îî‚îÄ‚îÄ training_materials.md   # Material de capacitaci√≥n
```

## ‚ö†Ô∏è Principios de Seguridad Fundamentales

### Reglas de Oro

1. **NUNCA comprometer la seguridad por velocidad de desarrollo**
2. **SIEMPRE tener E-stop f√≠sico accesible**
3. **NUNCA dejar robot operando sin supervisi√≥n**
4. **SIEMPRE probar en entorno controlado primero**
5. **VERIFICAR lista de seguridad antes de CADA prueba**

### Leyes de la Rob√≥tica (Asimov - Filos√≥ficas)

1. Un robot no puede da√±ar a un ser humano o, por inacci√≥n, permitir que un ser humano sufra da√±o
2. Un robot debe obedecer las √≥rdenes dadas por los seres humanos, excepto si estas √≥rdenes entrasen en conflicto con la Primera Ley
3. Un robot debe proteger su propia existencia en la medida en que esta protecci√≥n no entre en conflicto con la Primera o la Segunda Ley

## üö® Checklist de Seguridad Pre-Prueba

**‚ö†Ô∏è OBLIGATORIO antes de CADA sesi√≥n de pruebas**

### Hardware
- [ ] **Bater√≠a**
  - [ ] Voltaje verificado (no sobredescargada)
  - [ ] Conexiones aseguradas
  - [ ] BMS funcionando
  - [ ] Sin hinchaz√≥n visible
  
- [ ] **E-stop (Parada de Emergencia)**
  - [ ] Bot√≥n f√≠sico accesible
  - [ ] Probado y funcional
  - [ ] Corta alimentaci√≥n a motores
  
- [ ] **Estructura Mec√°nica**
  - [ ] Sin grietas o da√±os visibles
  - [ ] Tornillos apretados
  - [ ] Articulaciones se mueven libremente
  - [ ] No hay piezas sueltas
  
- [ ] **Cableado**
  - [ ] Sin cables pelados o expuestos
  - [ ] Conexiones seguras
  - [ ] Cable management ordenado
  - [ ] Sin signos de sobrecalentamiento

### Software
- [ ] **L√≠mites de Movimiento**
  - [ ] Rangos articulares configurados
  - [ ] Software limits implementados
  - [ ] Validados en prueba lenta
  
- [ ] **Emergency Stop en Software**
  - [ ] Implementado en c√≥digo
  - [ ] Probado
  - [ ] Timeout de watchdog configurado
  
- [ ] **Logging**
  - [ ] Sistema de logs activado
  - [ ] Grabando datos importantes
  
- [ ] **Comunicaci√≥n**
  - [ ] Conexi√≥n estable verificada
  - [ ] No hay lag significativo
  - [ ] Fallback si se pierde conexi√≥n

### Entorno
- [ ] **√Årea de Prueba**
  - [ ] Espacio despejado (m√≠n. 3m x 3m)
  - [ ] Superficie plana
  - [ ] Sin personas u objetos fr√°giles cerca
  - [ ] Buena iluminaci√≥n
  
- [ ] **Personal**
  - [ ] Solo personal autorizado presente
  - [ ] Todos conocen ubicaci√≥n de E-stop
  - [ ] Comunicaci√≥n clara establecida
  
- [ ] **Equipamiento de Seguridad**
  - [ ] Extintor accesible (para bater√≠as LiPo)
  - [ ] Kit de primeros auxilios disponible
  - [ ] Gafas de protecci√≥n (si aplica)

### Procedimiento
- [ ] **Plan de Prueba Definido**
  - [ ] Objetivos claros
  - [ ] Secuencia de pasos
  - [ ] Criterios de √©xito/fallo
  
- [ ] **Progresi√≥n Gradual**
  - [ ] Comenzar con movimientos lentos
  - [ ] Un sistema a la vez
  - [ ] Incrementar complejidad gradualmente

## üìã Procedimientos de Emergencia

### Parada de Emergencia

**Si algo va mal**:
1. **PRESIONAR E-STOP inmediatamente**
2. No intentar "salvar" el robot - seguridad primero
3. Desconectar bater√≠a si hay riesgo el√©ctrico
4. Evaluar situaci√≥n antes de reiniciar
5. Registrar incidente

### Incendio de Bater√≠a LiPo

**‚ö†Ô∏è LiPo en llamas no pueden extinguirse con agua**

1. **Activar E-stop**
2. **Evacuar √°rea inmediata**
3. **Usar extintor tipo D** (para metales) o arena
4. Si no es seguro: Dejar que se consuma en √°rea segura
5. **NO inhalar humo** (extremadamente t√≥xico)
6. Llamar a emergencias si es severo

**Prevenci√≥n**:
- Nunca sobrecargar o sobredescargar
- Almacenar en bolsa LiPo resistente al fuego
- Cargar con supervisi√≥n
- Desechar si est√° hinchada o da√±ada

### Choque El√©ctrico

1. **NO tocar a la persona** si a√∫n est√° en contacto
2. **Desconectar alimentaci√≥n** (E-stop, desenchufar)
3. Llamar a emergencias si es severo
4. Primeros auxilios si est√° capacitado

**Prevenci√≥n**:
- No trabajar en circuitos energizados innecesariamente
- Aislar componentes de alto voltaje
- Usar herramientas aisladas

### Da√±o F√≠sico (Robot golpea algo/alguien)

1. **E-stop inmediato**
2. Evaluar da√±os (personas > robot)
3. Primeros auxilios si necesario
4. An√°lisis de causa ra√≠z
5. Implementar mitigaciones antes de continuar

## üîí Seguridad en Software

### L√≠mites de Seguridad

**Implementar en TODOS los controladores**:
```python
class SafeJoint:
    """
    Articulaci√≥n con l√≠mites de seguridad
    """
    def __init__(self, name, min_angle, max_angle, max_speed, max_torque):
        self.name = name
        self.min_angle = min_angle
        self.max_angle = max_angle
        self.max_speed = max_speed  # deg/s
        self.max_torque = max_torque  # N¬∑m
        self.current_angle = 0
        self.emergency_stop = False
    
    def move_to(self, target_angle, speed):
        """
        Mueve con validaci√≥n de seguridad
        """
        if self.emergency_stop:
            logger.error(f"{self.name}: E-stop activado")
            return False
        
        # Validar rango
        if not (self.min_angle <= target_angle <= self.max_angle):
            logger.error(f"{self.name}: √Ångulo {target_angle} fuera de rango [{self.min_angle}, {self.max_angle}]")
            return False
        
        # Validar velocidad
        if abs(speed) > self.max_speed:
            logger.warning(f"{self.name}: Velocidad {speed} excede m√°ximo {self.max_speed}, limitando")
            speed = np.sign(speed) * self.max_speed
        
        # Aplicar movimiento
        self.current_angle = target_angle
        return True
    
    def estop(self):
        """Parada de emergencia"""
        self.emergency_stop = True
        logger.critical(f"{self.name}: EMERGENCY STOP")
        # Detener motor inmediatamente
        self.motor.stop()
```

### Watchdog Timer

**Detectar software colgado**:
```python
import threading
import time

class Watchdog:
    """
    Watchdog para detectar si el sistema se cuelga
    """
    def __init__(self, timeout=2.0, callback=None):
        self.timeout = timeout
        self.callback = callback or self.default_callback
        self.last_kick = time.time()
        self.running = True
        
        self.thread = threading.Thread(target=self._monitor, daemon=True)
        self.thread.start()
    
    def kick(self):
        """Reset watchdog - llamar regularmente en loop principal"""
        self.last_kick = time.time()
    
    def _monitor(self):
        while self.running:
            if time.time() - self.last_kick > self.timeout:
                logger.critical("WATCHDOG TIMEOUT - Sistema no responde")
                self.callback()
            time.sleep(0.1)
    
    def default_callback(self):
        """Acci√≥n por defecto si timeout"""
        # Activar E-stop
        robot.emergency_stop()
        # Enviar alerta
        send_alert("Watchdog timeout - robot detenido")
    
    def stop(self):
        self.running = False

# Uso en loop principal
watchdog = Watchdog(timeout=2.0)

while True:
    watchdog.kick()  # Indicar que estamos vivos
    
    # Procesamiento normal
    robot.update()
    
    time.sleep(0.01)  # 100 Hz
```

### Validaci√≥n de Inputs

**Nunca confiar en inputs externos**:
```python
def validate_command(command):
    """
    Valida comando antes de ejecutar
    """
    # Verificar estructura
    if not isinstance(command, dict):
        return False, "Comando debe ser diccionario"
    
    if 'type' not in command:
        return False, "Falta campo 'type'"
    
    # Validar tipo de comando
    valid_types = ['move', 'stop', 'calibrate', 'status']
    if command['type'] not in valid_types:
        return False, f"Tipo '{command['type']}' no v√°lido"
    
    # Validar par√°metros espec√≠ficos
    if command['type'] == 'move':
        if 'joint' not in command or 'angle' not in command:
            return False, "Comando move requiere 'joint' y 'angle'"
        
        # Validar rango (pre-check antes de enviar a SafeJoint)
        joint_limits = get_joint_limits(command['joint'])
        if not (joint_limits['min'] <= command['angle'] <= joint_limits['max']):
            return False, f"√Ångulo fuera de rango para {command['joint']}"
    
    return True, "OK"

# Uso
received_command = {'type': 'move', 'joint': 'elbow', 'angle': 45}

valid, message = validate_command(received_command)
if valid:
    execute_command(received_command)
else:
    logger.warning(f"Comando rechazado: {message}")
```

## ü§ù √âtica en IA y Rob√≥tica

### Principios √âticos del Proyecto

1. **Transparencia**: El comportamiento del robot debe ser predecible y explicable
2. **Equidad**: No discriminar por g√©nero, edad, etnia, etc.
3. **Privacidad**: Respetar datos personales
4. **Responsabilidad**: Hacernos responsables de las acciones del robot
5. **Beneficencia**: Dise√±ar para ayudar, no da√±ar

### Privacidad de Datos

**Datos sensibles a proteger**:
- Im√°genes/video de caras ‚Üí **Anonimizar o pedir consentimiento**
- Grabaciones de audio ‚Üí **Solo con consentimiento**
- Ubicaci√≥n del hogar ‚Üí **No compartir**
- Patrones de comportamiento ‚Üí **Anonimizar**

**Implementaci√≥n**:
```python
import hashlib
import cv2

def anonymize_face(image):
    """
    Difumina rostros en imagen
    """
    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
    faces = face_cascade.detectMultiScale(image, 1.3, 5)
    
    for (x, y, w, h) in faces:
        # Difuminar rostro
        face_region = image[y:y+h, x:x+w]
        blurred = cv2.GaussianBlur(face_region, (99, 99), 30)
        image[y:y+h, x:x+w] = blurred
    
    return image

def collect_telemetry(user_id, robot_state):
    """
    Recolecta telemetr√≠a sin datos personales
    """
    # Anonimizar ID de usuario
    anon_id = hashlib.sha256(user_id.encode()).hexdigest()
    
    telemetry = {
        'user': anon_id,
        'timestamp': time.time(),
        'battery_level': robot_state['battery'],
        'position': 'anonymized',  # No guardar posici√≥n exacta
        'task_success': robot_state['task_completed']
    }
    
    # Guardar sin informaci√≥n personal identificable
    save_telemetry(telemetry)
```

### Detecci√≥n de Sesgo en Modelos

**Evaluar equidad**:
```python
def evaluate_model_fairness(model, test_data, sensitive_attributes=['age', 'gender']):
    """
    Eval√∫a si modelo tiene sesgo respecto a atributos sensibles
    
    Nota: Solo usar atributos sensibles donde sea legal y √©tico
    """
    results = {}
    
    for attr in sensitive_attributes:
        groups = test_data.groupby(attr)
        accuracies = {}
        
        for group_name, group_data in groups:
            predictions = model.predict(group_data['features'])
            accuracy = (predictions == group_data['labels']).mean()
            accuracies[group_name] = accuracy
        
        # Calcular disparidad
        max_acc = max(accuracies.values())
        min_acc = min(accuracies.values())
        disparity = max_acc - min_acc
        
        results[attr] = {
            'accuracies': accuracies,
            'disparity': disparity,
            'fair': disparity < 0.1  # Umbral del 10%
        }
        
        if disparity > 0.1:
            logger.warning(f"Posible sesgo en {attr}: {accuracies}")
    
    return results
```

## üìä An√°lisis de Riesgos (FMEA)

### Ejemplo: Failure Mode and Effects Analysis

| ID | Modo de Fallo | Causa | Efecto | Severidad (1-10) | Probabilidad (1-10) | Detecci√≥n (1-10) | RPN | Mitigaci√≥n |
|----|---------------|-------|--------|------------------|---------------------|------------------|-----|------------|
| R1 | Servo falla | Sobrecarga, defecto | P√©rdida de control articulaci√≥n | 7 | 4 | 3 | 84 | Monitoreo corriente, redundancia |
| R2 | Software crash | Bug, overflow | Movimiento err√°tico | 9 | 3 | 5 | 135 | Watchdog, testing exhaustivo |
| R3 | Bater√≠a se agota | Uso prolongado | Parada s√∫bita | 6 | 7 | 2 | 84 | Monitor bater√≠a, alerta temprana |
| R4 | P√©rdida WiFi | Interferencia | P√©rdida de control | 8 | 5 | 3 | 120 | Failsafe autom√°tico, modo aut√≥nomo |
| R5 | Sensor IMU falla | Vibraci√≥n, defecto | P√©rdida equilibrio | 9 | 2 | 6 | 108 | Fusi√≥n multi-sensor, validaci√≥n |

**RPN = Severidad √ó Probabilidad √ó Detecci√≥n**
Priorizar si RPN > 100

## üìù Reporte de Incidentes

### Template

```markdown
# Reporte de Incidente - [FECHA]

## Informaci√≥n General
- **Fecha**: YYYY-MM-DD HH:MM
- **Ubicaci√≥n**: [Lugar del incidente]
- **Reportado por**: [Nombre]
- **Severidad**: [Baja / Media / Alta / Cr√≠tica]

## Descripci√≥n del Incidente
[Descripci√≥n detallada de qu√© sucedi√≥]

## Causa Ra√≠z
[Qu√© caus√≥ el incidente - si se conoce]

## Impacto
- **Da√±os f√≠sicos**: [Descripci√≥n]
- **Da√±os al robot**: [Descripci√≥n]
- **Tiempo de inactividad**: [X horas]

## Acciones Inmediatas
1. [Acci√≥n tomada inmediatamente]
2. [Otra acci√≥n]

## Acciones Correctivas
1. [Acci√≥n para prevenir recurrencia]
2. [Otra acci√≥n]

## Lecciones Aprendidas
- [Lecci√≥n 1]
- [Lecci√≥n 2]

## Seguimiento
- [ ] Implementar acci√≥n correctiva 1
- [ ] Implementar acci√≥n correctiva 2
- [ ] Revisar procedimientos
- [ ] Actualizar documentaci√≥n
```

## üìö Normativas y Est√°ndares

### ISO/TS 15066: Robots Colaborativos
- L√≠mites de fuerza y presi√≥n en contacto humano-robot
- Movimiento a velocidad segura (<250 mm/s en zona colaborativa)
- Detecci√≥n de colisi√≥n

### ISO 13482: Robots de Cuidado Personal
- Requisitos de seguridad para robots que asisten personas
- Mitigaci√≥n de riesgos

### ISO 10218: Robots Industriales
- Seguridad general de robots
- Paradas de emergencia
- Modos de operaci√≥n

### IEC 60950/62368: Seguridad El√©ctrica
- Protecci√≥n contra choques el√©ctricos
- Aislamiento
- Materiales retardantes de llama

## üéì Capacitaci√≥n Obligatoria

**Antes de operar el robot, cada persona debe**:
1. Leer este documento completo
2. Conocer ubicaci√≥n y uso de E-stop
3. Conocer procedimientos de emergencia
4. Entender l√≠mites del robot
5. Firmar documento de conocimiento (si es proyecto institucional)

## Pr√≥ximos Pasos

1. **Completar an√°lisis FMEA** para todos los subsistemas
2. **Implementar E-stop** f√≠sico y en software
3. **Crear checklist f√≠sico** impreso y en ubicaci√≥n visible
4. **Configurar sistema de logging** de eventos de seguridad
5. **Realizar simulacro** de emergencia

## Referencias

- üìñ "Robot Ethics" - Lin, Abney, Bekey
- üìñ "AI Ethics" - Coeckelbergh
- üåê ISO Standards: www.iso.org
- üåê EU AI Act
- üåê IEEE Ethically Aligned Design
- üåê Battery University (seguridad LiPo)

---

**‚ö†Ô∏è RECORDATORIO**: La seguridad NO es opcional. Si hay dudas sobre la seguridad de una operaci√≥n, DETENER y consultar.

**√öltima actualizaci√≥n**: Febrero 2026